{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikeras\n",
    "from scikeras import KerasClassifier\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class KerasClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, build_fn=None, epochs=1, batch_size=32, verbose=0):\n",
    "        self.build_fn = build_fn\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.model_ = None\n",
    "    def fit(self, X, y):\n",
    "        self.model_ = self.build_fn()\n",
    "        self.model_.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose)\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return (self.model_.predict(X)>0.5).astype('int32')\n",
    "    def predict_proba(self, X):\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "# Define your Keras model building function\n",
    "def build_fn():\n",
    "    model = Sequential([\n",
    "        Dense(12, input_dim=8, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize your KerasClassifier with the build function and other parameters\n",
    "model = KerasClassifier(build_fn=build_fn, epochs=1, batch_size=32, verbose=0)\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# image crop\n",
    "def crop_knee(image, crop_height, crop_width):\n",
    "  h, w = image.shape[:2]\n",
    "  center = (h//2, w//2)\n",
    "  cropped_img = image[\n",
    "      center[0] - crop_height//2 : center[0] + crop_height//2,\n",
    "      center[1] - crop_width//2 : center[1] + crop_width//2\n",
    "  ]\n",
    "  return cropped_img\n",
    "\n",
    "# HE CLAHE\n",
    "def apply_clahe(image):\n",
    "  clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(8, 8))\n",
    "  return clahe.apply(image)\n",
    "\n",
    "# equalize-normalize\n",
    "def processed(image):\n",
    "    # equalized = cv2.equalizeHist(image)\n",
    "    normalized = cv2.normalize(image, None, 0,255, cv2.NORM_MINMAX)\n",
    "    return normalized\n",
    "\n",
    "# Data Load & Preprocessing\n",
    "def process_load_img(input_dir, crop_height, crop_width):\n",
    "  images = []\n",
    "  labels = []\n",
    "  for class_folder in os.listdir(input_dir):\n",
    "    class_input_path = os.path.join(input_dir, class_folder)\n",
    "    class_label = int(class_folder)\n",
    "    print(f\"class_folder:{class_input_path}\")\n",
    "    print(\"==============================\")\n",
    "    \n",
    "    for img_file in os.listdir(class_input_path):\n",
    "      img_path = os.path.join(input_dir, class_folder)\n",
    "      img_r_path = os.path.join(img_path, img_file)\n",
    "      print(f\"img path: {img_path}\")\n",
    "      print(\"==============================\")\n",
    "      \n",
    "      img = cv2.imread(img_r_path, cv2.IMREAD_GRAYSCALE)\n",
    "      print(f\"img:{img}\")\n",
    "      \n",
    "      if img is not None:\n",
    "        cropped_img = crop_knee(img, crop_height, crop_width) # 그려서\n",
    "        clahe_img = apply_clahe(cropped_img) # 전처리\n",
    "        prep_img = processed(clahe_img)\n",
    "        images.append(prep_img) \n",
    "        labels.append(class_label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Data Merge & Split(new dataset)\n",
    "def merge_split_datas(train_dir, val_dir, crop_height, crop_width, test_size=.2):\n",
    "  X_train, y_train = process_load_img(train_dir, crop_height, crop_width)\n",
    "  X_val, y_val = process_load_img(val_dir, crop_height, crop_width)\n",
    "  X_comb = np.concatenate((X_train, X_val), axis=0)\n",
    "  y_comb = np.concatenate((y_train, y_val), axis=0)\n",
    "  X_train_n, X_val_n, y_train_n, y_val_n = train_test_split(X_comb, y_comb, test_size=test_size, random_state=42, stratify=y_comb)\n",
    "  return X_train_n, X_val_n, y_train_n, y_val_n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dir = './datas/osteoarthritis/train'\n",
    "val_dir = './datas/osteoarthritis/val'\n",
    "\n",
    "crop_height = 256\n",
    "crop_width = 256\n",
    "\n",
    "def test_load_img(test_dir, t_crop_height, t_crop_width):\n",
    "  t_images = []\n",
    "  t_labels = []\n",
    "  for class_folder in os.listdir(test_dir):\n",
    "    # 0, 1, 2, 3, 4\n",
    "    class_input_path = os.path.join(test_dir, class_folder)\n",
    "    class_label = int(class_folder)\n",
    "    print(f\"class_folder:{class_input_path}\")\n",
    "    print(\"==============================\")\n",
    "    \n",
    "    for img_file in os.listdir(class_input_path):\n",
    "      img_path = os.path.join(test_dir, class_folder)\n",
    "      img_path = os.path.join(img_path, img_file)\n",
    "      print(f\"img path: {img_path}\")\n",
    "      print(\"==============================\")\n",
    "      \n",
    "      img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "      print(f\"img:{img}\")\n",
    "      \n",
    "  return np.array(t_images), np.array(t_labels)\n",
    "\n",
    "# process_load_img(train_dir, crop_height, crop_width)\n",
    "t_crop_height = 256\n",
    "t_crop_width = 256\n",
    "test_dir = './datas/osteoarthritis/test'\n",
    "X_test,y_test = test_load_img(test_dir, t_crop_height, t_crop_width)\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50, DenseNet121\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input, Conv2D\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "input_shape = (crop_height, crop_width)\n",
    "class_num = 5\n",
    "\n",
    "def create_model(model_name='Resnet50', optimizer='adam', dropout_rate=.5, fc_units=512, class_num=class_num):\n",
    "  input_layer = Input(shape=input_shape)\n",
    "  conv_layer = Conv2D(3, (3, 3), padding='same')(input_layer)\n",
    "  if model_name == 'ResNet50':\n",
    "    base = ResNet50(weights='imagenet', include_top=False, input_shape=(crop_height, crop_width))\n",
    "  elif model_name == 'VGG16':\n",
    "    base = VGG16(weights='imagenet', include_top=False, input_shape=(crop_height, crop_width))\n",
    "  else:\n",
    "    base = DenseNet121(weights='imagenet', include_top=False, input_shape=(crop_height, crop_width))\n",
    "    \n",
    "  base_out = base(conv_layer)\n",
    "  flatten = Flatten()(base_out)\n",
    "  fc = Dense(fc_units, activation='relu')(flatten)\n",
    "  dropout = Dropout(dropout_rate)(fc)\n",
    "  output = Dense(class_num, activation='softmax')(dropout)\n",
    "  model = Model(inputs=input_layer, outputs=output)\n",
    "  model.Compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "param_grid = {\n",
    "    'model_name':['ResNet50', 'DenseNet', 'VGG16'],\n",
    "    'batch_size':[16, 32],\n",
    "    'epochs':[30, 50, 80],\n",
    "    'optimizer':['adam', 'rmsprop']\n",
    "    # 'dropout_rate':[0.2, 0.4, 0.5],\n",
    "    # 'fc_units':[512, 1024]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_res = grid.fit(X_train_n, y_train_n)\n",
    "means = grid_res.cv_results_['mean_test_score']\n",
    "std = grid_res.cv_results_['std_test_score']\n",
    "params = grid_res.cv_results_['params']\n",
    "best_model = grid_res.best_estimator_.model\n",
    "\n",
    "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "X_train_n, X_val_n, y_train_n, y_val_n = merge_split_datas(train_dir, val_dir, crop_height, crop_width, test_size=.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
